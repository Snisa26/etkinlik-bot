# scrape_passo.py
import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import urljoin
from geocode import get_coordinates
import time
import sys
import json

def scrape_passo():
    url = "https://passo.com.tr/etkinlikler?sehir=TÃ¼rkiye"
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/128.0.0.0 Safari/537.36",
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
        "Accept-Language": "tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7",
        "Connection": "keep-alive",
    }

    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.raise_for_status()
    except Exception as e:
        print(f"Sayfa aÃ§Ä±lamadÄ±: {e}", file=sys.stderr)
        return []

    # Kodlama hatasÄ± olmamasÄ± iÃ§in
    response.encoding = 'utf-8'
    soup = BeautifulSoup(response.text, 'html.parser')

    # Etkinlik kartlarÄ±nÄ± bul
    event_items = soup.find_all("div", class_="event-card")  # GerÃ§ek sÄ±nÄ±f adÄ± kontrol edilecek

    events = []

    for item in event_items[:10]:
        try:
            # BaÅŸlÄ±k
            title_elem = item.find("h3", class_="event-title")
            if not title_elem:
                title_elem = item.find("a", class_="event-link")  # Alternatif
            title = title_elem.get_text(strip=True) if title_elem else "Etkinlik Ä°smi Yok"

            # Tarih
            date_elem = item.find("div", class_="event-date")
            date_text = date_elem.get_text(strip=True) if date_elem else "Tarih Yok"
            # Basit tarih formatÄ±: "12 EylÃ¼l" â†’ "2025-09-12"
            match = re.search(r'(\d{1,2})\s+(\w+)', date_text)
            if match:
                day = match.group(1)
                month_tr = match.group(2)
                months = {"Ocak": "01", "Åubat": "02", "Mart": "03", "Nisan": "04",
                         "MayÄ±s": "05", "Haziran": "06", "Temmuz": "07", "AÄŸustos": "08",
                         "EylÃ¼l": "09", "Ekim": "10", "KasÄ±m": "11", "AralÄ±k": "12"}
                month = months.get(month_tr, "01")
                year = "2025"
                formatted_date = f"{year}-{month}-{day.zfill(2)}"
            else:
                formatted_date = "2025-01-01"

            # Mekan
            venue_elem = item.find("div", class_="event-location")
            venue = venue_elem.get_text(strip=True) if venue_elem else "Mekan Bilinmiyor"

            # Link
            link_elem = item.find("a", href=True)
            link = urljoin("https://passo.com.tr", link_elem['href']) if link_elem else "#"

            # ğŸ—ºï¸ Mekan adÄ± dÃ¼zeltme (Mapping)
            venue_mapping = {
                "Zorlu Center": "Zorlu Center",
                "Vodafone Park": "Vodafone Park",
                "KÃ¼Ã§Ã¼kÃ§iftlik ParkÄ±": "KÃ¼Ã§Ã¼kÃ§iftlik Park",
                "BostancÄ± GÃ¶steri Merkezi": "BostancÄ± GÃ¶steri Merkezi",
                "BeÅŸiktaÅŸ Stadyumu": "Vodafone Park",
                "ÅÃ¼krÃ¼ SaracoÄŸlu": "Vodafone Park"
            }
            cleaned_venue = venue_mapping.get(venue, venue)

            # ğŸŒ KOORDÄ°NAT AL
            print(f"ğŸ” {cleaned_venue} iÃ§in koordinat aranÄ±yor...", file=sys.stderr)
            lat, lng = get_coordinates(cleaned_venue)
            time.sleep(1)  # Rate limit

            events.append({
                "ad": title,
                "tarih": formatted_date,
                "saat": "19:00",  # GerÃ§ek saat yok, tahmini
                "mekan_adi": venue,
                "link": link,
                "aciklama": f"{title} etkinliÄŸi iÃ§in detay: {link}",
                "latitude": lat,
                "longitude": lng
            })
        except Exception as e:
            print(f"Veri hatasÄ± (passo): {e}", file=sys.stderr)
            continue

    print(f"{len(events)} etkinlik Ã§ekildi.", file=sys.stderr)
    return events

# ğŸš€ Ana iÅŸlem
if __name__ == "__main__":
    events = scrape_passo()
    json.dump(events, sys.stdout)
    sys.stdout.flush()